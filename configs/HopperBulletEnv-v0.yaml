experiment_name: Mlp

task_name: HopperBulletEnv-v0
alg: PPO
policy: MlpPolicy

device: cuda:0

total_timesteps: 1000000
n_steps: 1024
batch_size: 64