experiment_name: 'GNN_cheetah_flat_v2_5M_3e5_tanh'
task_name: HalfCheetahBulletEnv-v0
alg: PPO
policy: GnnPolicy_V2

device: cuda:0

drop_body_nodes: True
use_sibling_relations: False

# ["action_per_controller", "pooled", "pooled_by_group", "flattened"]
policy_readout_mode: 'flattened'

gnn_for_values: False
learning_rate: !!float 3e-5

total_timesteps: !!float 5e6
n_envs: 1
n_steps: 1024
batch_size: 64
activation_fn: Tanh

net_arch:
  input:
    - [Linear, 256]
    - [Linear, 256]
  propagate:
    - [NerveNetConv, 128]
    - [NerveNetConv, 128]
    - [NerveNetConv, 128]
    - [NerveNetConv, 128]
  policy:
    - [Linear, 256]
    - [Linear, 256]
  value:
    - [Linear, 256]
    - [Linear, 256]
